{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run dataloader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=500\n",
    "train_dataloader = DataLoader(train_set, collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_set, collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, collate_fn=collate_fn, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 'cuda:3'\n",
    "device = torch.device(gpu_id if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2071247/4016921915.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_w=np.array(self.language_sdk[hid]['context_embedding_indexes'])\n",
      "/tmp/ipykernel_2071247/4016921915.py:103: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_of=np.array(self.word_aligned_openface_sdk[hid]['context_features'])\n",
      "/tmp/ipykernel_2071247/4016921915.py:104: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_cvp=np.array(self.word_aligned_covarep_sdk[hid]['context_features'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486\n",
      "486\n"
     ]
    }
   ],
   "source": [
    "humor = 0\n",
    "no_humor = 0\n",
    "for batch_idx, batch in enumerate(dev_dataloader, 0):\n",
    "    x_p,x_c,y,hid,x_p_len=map(lambda x: x.to(device), batch)\n",
    "    for label in y:\n",
    "        if label == 0:\n",
    "            no_humor += 1\n",
    "        if label == 1:\n",
    "            humor += 1\n",
    "\n",
    "print(humor)\n",
    "print(no_humor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "          \n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 81 ==> 8\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(81, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 8)\n",
    "        )\n",
    "          \n",
    "        # Building an linear decoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 8 ==> 81\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(8, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 81),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "          \n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 81 ==> 8\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(752, 512),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(256, 128)\n",
    "        )\n",
    "          \n",
    "        # Building an linear decoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 8 ==> 81\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 256),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(256, 512),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(512, 752)\n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn\n",
    "class RNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_layer_size_1, hidden_layer_size_2) -> None:\n",
    "        super().__init__()\n",
    "        #self.rnn1_s0 = torch.nn.Parameter(torch.tensor(np.random.normal(0.0, 1.0, (hidden_layer_size_1,)), dtype=torch.float32))\n",
    "        #self.rnn1_c0 = torch.nn.Parameter(torch.tensor(np.random.normal(0.0, 1.0, (hidden_layer_size_1,)), dtype=torch.float32))\n",
    "        #self.rnn2_s0 = torch.nn.Parameter(torch.tensor(np.random.normal(0.0, 1.0, (hidden_layer_size_1,)), dtype=torch.float32))\n",
    "        #self.rnn2_c0 = torch.nn.Parameter(torch.tensor(np.random.normal(0.0, 1.0, (hidden_layer_size_1,)), dtype=torch.float32))\n",
    "        self.rnn = torch.nn.LSTM(input_dim, hidden_layer_size_1, batch_first=True, num_layers=2)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        #self.w1 = torch.nn.Parameter(torch.tensor(np.random.normal(0.0, 1.0, (hidden_layer_size_1, hidden_layer_size_2)), dtype=torch.float32))\n",
    "        #self.b1 = torch.nn.Parameter(torch.zeros((1,), dtype=torch.float32))\n",
    "        self.linear = torch.nn.Linear(hidden_layer_size_1, 1)\n",
    "\n",
    "    def forward(self, x, text_lens):\n",
    "        batch_size = x.shape[0]\n",
    "        '''\n",
    "        s0 = torch.stack((\n",
    "            self.rnn1_s0,\n",
    "            self.rnn2_s0,\n",
    "        ), dim=0)\n",
    "        s0 = s0.unsqueeze(1).tile((1, batch_size, 1))\n",
    "\n",
    "        c0 = torch.stack((\n",
    "            self.rnn1_c0,\n",
    "            self.rnn2_c0,\n",
    "        ), dim=0)\n",
    "        c0 = c0.unsqueeze(1).tile((1, batch_size, 1))\n",
    "        '''\n",
    "\n",
    "        interm_states, _ = self.rnn(x)\n",
    "        final_state = interm_states[torch.arange(batch_size), text_lens - 1, :]\n",
    "        #hidden = torch.nn.functional.leaky_relu(final_state@self.w1 + self.b1)\n",
    "        h = self.dropout(final_state)\n",
    "        return self.linear(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3296201/4016921915.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_w=np.array(self.language_sdk[hid]['context_embedding_indexes'])\n",
      "/tmp/ipykernel_3296201/4016921915.py:103: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_of=np.array(self.word_aligned_openface_sdk[hid]['context_features'])\n",
      "/tmp/ipykernel_3296201/4016921915.py:104: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_cvp=np.array(self.word_aligned_covarep_sdk[hid]['context_features'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.7068066596984863\n",
      "dev accuracy: 54.84%\n",
      "2 0.6906037926673889\n",
      "dev accuracy: 53.91%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3296201/3893316298.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_p_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx_p_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3296201/4016921915.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mx_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded_punchline_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpunchline_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpunchline_of\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpunchline_cvp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sen_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m#context feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mx_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded_context_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_of\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_cvp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_context_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sen_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhumor_label_sdk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3296201/4016921915.py\u001b[0m in \u001b[0;36mpadded_context_features\u001b[0;34m(self, context_w, context_of, context_cvp, max_context_len, max_sen_len)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mpadded_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mp_seq_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaded_word_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_sen_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mp_seq_cvp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded_covarep_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_cvp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_sen_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mp_seq_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mpadded_openface_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_of\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_sen_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3296201/4016921915.py\u001b[0m in \u001b[0;36mpaded_word_idx\u001b[0;34m(self, seq, max_sen_len, left_pad)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mseq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_sen_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mpad_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_sen_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mpad_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embedding_list_sdk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpad_w\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpad_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# input features\n",
    "###\n",
    "#idxs = torch.arange(300) # text, 300\n",
    "#idxs = torch.arange(300, 381) # speech, 81\n",
    "#idxs = torch.arange(381, 752) # visual, 371\n",
    "#idxs = torch.arange(381) # text + speech, 381\n",
    "#idxs = torch.cat((torch.arange(300), torch.arange(381, 752))) # text + visual, 671\n",
    "#idxs = torch.arange(300, 752) # speech + visual, 452\n",
    "idxs = torch.arange(752) # text + speech + visual, 752\n",
    "\n",
    "ae = torch.load('autoencoder_all_2.pth')\n",
    "ae.to(device)\n",
    "\n",
    "device = torch.device(gpu_id if torch.cuda.is_available() else 'cpu')\n",
    "rnn = RNN(input_dim=1024, hidden_layer_size_1=512, hidden_layer_size_2=128)\n",
    "rnn.to(device)\n",
    "\n",
    "optimiser = torch.optim.Adam(rnn.parameters(), lr=0.0001)\n",
    "epochs = 100\n",
    "patience = 20\n",
    "\n",
    "print('step', 'error')\n",
    "dev_accs = []\n",
    "best_dev_acc = 0\n",
    "errors = []\n",
    "num_bad_epochs = 0\n",
    "num_epochs = 0\n",
    "best_epoch = 0\n",
    "for epoch in range(1, epochs+1):\n",
    "    for batch_idx, batch in enumerate(train_dataloader, 0):\n",
    "        x_p,x_c,y,hid,x_p_len=map(lambda x: x.to(device), batch)\n",
    "        x_p_transformed = []\n",
    "        for sent in x_p:\n",
    "            speech_feats = sent[:, idxs].detach().tolist()\n",
    "            speech_feats = torch.tensor(speech_feats, dtype=torch.float32, device=device)\n",
    "            with torch.no_grad():\n",
    "                speech_feats_transformed, _ = ae(speech_feats)\n",
    "            speech_feats_transformed = speech_feats_transformed.detach().tolist()\n",
    "            x_p_transformed.append(speech_feats_transformed)\n",
    "        x_p_transformed = torch.tensor(x_p_transformed, dtype=torch.float32, device=device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        output = rnn(x_p_transformed, x_p_len)\n",
    "        error = torch.nn.functional.binary_cross_entropy_with_logits(output, y)\n",
    "        error.backward()\n",
    "        optimiser.step()\n",
    "    \n",
    "    print(epoch, error.detach().tolist())\n",
    "    errors.append(error.detach().tolist())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        matches = 0\n",
    "        total = 0\n",
    "        for batch_idx, batch in enumerate(dev_dataloader, 0): \n",
    "            x_p,x_c,y,hid,x_p_len=map(lambda x: x.to(device), batch)\n",
    "            x_p_transformed = []\n",
    "            for sent in x_p:\n",
    "                speech_feats = sent[:, idxs].detach().tolist()\n",
    "                speech_feats = torch.tensor(speech_feats, dtype=torch.float32, device=device)\n",
    "                with torch.no_grad():\n",
    "                    speech_feats_transformed, _ = ae(speech_feats)\n",
    "                speech_feats_transformed = speech_feats_transformed.detach().tolist()\n",
    "                x_p_transformed.append(speech_feats_transformed)\n",
    "            x_p_transformed = torch.tensor(x_p_transformed, dtype=torch.float32, device=device)\n",
    "\n",
    "            outputs = torch.sigmoid(rnn(x_p_transformed, x_p_len))\n",
    "            predictions = (outputs > 0.5)*1\n",
    "            matches += (y == predictions).sum()\n",
    "            total += len(y)\n",
    "        acc = matches / total\n",
    "        dev_accs.append(float(acc))\n",
    "        print('dev accuracy: {:.2%}'.format(float(acc)))\n",
    "\n",
    "    if acc > best_dev_acc:\n",
    "        best_dev_acc = acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(rnn, 'punchline_rnn_text_speech_visual.pth')\n",
    "    else:\n",
    "        num_bad_epochs += 1\n",
    "        if num_bad_epochs == patience:\n",
    "            num_epochs = epoch\n",
    "            break\n",
    "\n",
    "plt.plot(range(1, num_epochs+1), dev_accs, 'b')\n",
    "plt.title('dev set accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, num_epochs+1), errors, 'r')\n",
    "plt.title('train error')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error')\n",
    "plt.show()\n",
    "\n",
    "print('best model after {} epochs with dev set accuracy {}'.format(best_epoch, best_dev_acc))\n",
    "rnn = torch.load('punchline_rnn_text_speech_visual.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1818251/4016921915.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_w=np.array(self.language_sdk[hid]['context_embedding_indexes'])\n",
      "/tmp/ipykernel_1818251/4016921915.py:103: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_of=np.array(self.word_aligned_openface_sdk[hid]['context_features'])\n",
      "/tmp/ipykernel_1818251/4016921915.py:104: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  context_cvp=np.array(self.word_aligned_covarep_sdk[hid]['context_features'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 63.67%\n"
     ]
    }
   ],
   "source": [
    "hid_humor_t = {}\n",
    "hid_humor_f = {}\n",
    "hid_nonhumor_t = {}\n",
    "hid_nonhumor_f = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    matches = 0\n",
    "    total = 0\n",
    "    for batch_idx, batch in enumerate(test_dataloader, 0): \n",
    "        x_p,x_c,y,hid, x_p_len=map(lambda x: x.to(device), batch)\n",
    "        outputs = torch.sigmoid(rnn(x_p[:, :, idxs], x_p_len))\n",
    "        predictions = (outputs > 0.5)*1\n",
    "        matches += (y == predictions).sum()\n",
    "        total += len(y)\n",
    "        for j, id in enumerate(hid.detach().tolist()):\n",
    "            if predictions[j] == 1 and y[j] == 1:\n",
    "                hid_humor_t[id] = outputs[j].detach().tolist()[0]\n",
    "            elif predictions[j] == 1 and y[j] == 0:\n",
    "                hid_humor_f[id] = outputs[j].detach().tolist()[0]\n",
    "            elif predictions[j] == 0 and y[j] == 0:\n",
    "                hid_nonhumor_t[id] = outputs[j].detach().tolist()[0]\n",
    "            elif predictions[j] == 0 and y[j] == 1:\n",
    "                hid_nonhumor_f[id] = outputs[j].detach().tolist()[0]\n",
    "            else:\n",
    "                print('something is wrong')\n",
    "    acc = matches / total\n",
    "    print('test accuracy: {:.2%}'.format(float(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n",
      "270\n",
      "220\n",
      "167\n",
      "the good news is i married her the next year\n",
      "i'm not going to talk about that tonight\n",
      "i haven't come to the best part\n",
      "but i still have six and a half minutes\n",
      "they probably should have marketed this as some of the guardians of the galaxy\n",
      "\n",
      "i said i'd like to be a writer\n",
      "another called twister and so on and so on\n",
      "i would have told you myself that i was the last person on earth who would stay with a man who beats me but in fact i was a very typical victim because of my age\n",
      "oh let me kind of tell you a funny little play bit\n",
      "you can experience their sense of place\n",
      "\n",
      "and you all have chosen your own instruments to fulfill this mission of creating a better world\n",
      "and the satellite imagery we have of it today is old\n",
      "and as you're thinking about this incredible ability to make life do what you want it to do what it's programmed to do what you end up doing is taking what we've been doing for thousands of years which is breeding changing mixing matching all kinds of life forms and we accelerate it\n",
      "for me my work is at all times building a nation out of thin air\n",
      "now people talk about this a lot and they talk about things like flextime and mentoring and programs companies should have to train women\n",
      "\n",
      "sorry about this jeff\n",
      "my hand is at risk here\n",
      "we're told what shape we're supposed to be in\n",
      "and maggie robbins said i used to volunteer in an aids clinic and i would just talk and talk and talk and the people i was dealing with weren't very responsive and i thought not very friendly or helpful of them\n",
      "one vendor will offer you fair trade organic cocaine\n"
     ]
    }
   ],
   "source": [
    "print(len(hid_humor_t))\n",
    "print(len(hid_nonhumor_t))\n",
    "print(len(hid_humor_f))\n",
    "print(len(hid_nonhumor_f))\n",
    "\n",
    "language_sdk=load_pickle(\"language_sdk.pkl\")\n",
    "\n",
    "sorted_humor_t = {k: v for k, v in sorted(hid_humor_t.items(), key=lambda item: item[1], reverse=True)}\n",
    "sorted_nonhumor_t = {k: v for k, v in sorted(hid_nonhumor_t.items(), key=lambda item: item[1], reverse=True)}\n",
    "sorted_humor_f = {k: v for k, v in sorted(hid_humor_f.items(), key=lambda item: item[1], reverse=True)}\n",
    "sorted_nonhumor_f = {k: v for k, v in sorted(hid_nonhumor_f.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "for hid, output in list(sorted_humor_t.items())[:5]:\n",
    "    print(language_sdk[hid]['punchline_sentence'])\n",
    "print()\n",
    "for hid, output in list(sorted_humor_f.items())[:5]:\n",
    "    print(language_sdk[hid]['punchline_sentence'])\n",
    "print()\n",
    "for hid, output in list(sorted_nonhumor_t.items())[:5]:\n",
    "    print(language_sdk[hid]['punchline_sentence'])\n",
    "print()\n",
    "for hid, output in list(sorted_nonhumor_f.items())[:5]:\n",
    "    print(language_sdk[hid]['punchline_sentence'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
